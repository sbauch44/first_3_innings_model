{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884b657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PA Outcome Scaler Creation Process...\n"
     ]
    }
   ],
   "source": [
    "# Create PA Outcome Scaler from Baseball Simulator Data\n",
    "# This notebook recreates the pa_outcome_scaler.joblib file using your data processing pipeline\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "sys.path.append(str(pathlib.Path(pathlib.Path.cwd()).parent))\n",
    "\n",
    "# Import your modules (adjust paths as needed)\n",
    "import baseball_simulator.config as config\n",
    "import baseball_simulator.data_processor as data_processor\n",
    "import baseball_simulator.storage as storage\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Starting PA Outcome Scaler Creation Process...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1504b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 1: Loading Historical PA Data ===\n",
      "Loaded 6602 historical PA records\n",
      "Columns available: ['game_pk', 'at_bat_number', 'pitch_number', 'batter', 'pitcher', 'events', 'stand', 'p_throws', 'inning_topbot', 'home_team', 'away_team', 'game_date', 'game_type', 'bb_type', 'balls', 'strikes', 'outs_when_up', 'inning', 'game_year', 'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6', 'fielder_7', 'fielder_8', 'fielder_9', 'pa_outcome_category', 'is_pa', 'is_ab', 'is_hit', 'is_k', 'is_bb', 'is_hbp', 'is_1b', 'is_2b', 'is_3b', 'is_hr', 'is_out']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the historical PA data with helpers\n",
    "print(\"\\n=== Step 1: Loading Historical PA Data ===\")\n",
    "try:\n",
    "    # Load the processed historical data\n",
    "    historical_pa_helpers_path = f\"{config.BASE_FILE_PATH}historical_pa_data_with_helpers.parquet\"\n",
    "    df_historical = pl.read_parquet(historical_pa_helpers_path)\n",
    "    print(f\"Loaded {df_historical.shape[0]} historical PA records\")\n",
    "    print(f\"Columns available: {df_historical.columns}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading historical data: {e}\")\n",
    "    print(\"Please ensure the historical_pa_data_with_helpers.parquet file exists\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3465dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 2: Processing Data for Daily Stats ===\n",
      "Calculating batter daily totals...\n",
      "Calculating pitcher daily totals...\n",
      "Calculating cumulative batter stats...\n",
      "Calculating cumulative pitcher stats...\n",
      "Applying ballast and calculating final rolling stats...\n",
      "Processed batter stats shape: (1778, 31)\n",
      "Processed pitcher stats shape: (754, 31)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Process the data to get daily stats (like in your pipeline)\n",
    "print(\"\\n=== Step 2: Processing Data for Daily Stats ===\")\n",
    "\n",
    "# Calculate daily totals\n",
    "print(\"Calculating batter daily totals...\")\n",
    "df_batter_daily = data_processor.calculate_batter_daily_totals(df_historical)\n",
    "\n",
    "print(\"Calculating pitcher daily totals...\")\n",
    "df_pitcher_daily = data_processor.calculate_pitcher_daily_totals(df_historical)\n",
    "\n",
    "# Calculate cumulative stats\n",
    "print(\"Calculating cumulative batter stats...\")\n",
    "df_batter_daily = data_processor.calculate_cumulative_batter_stats(df_batter_daily)\n",
    "\n",
    "print(\"Calculating cumulative pitcher stats...\")\n",
    "df_pitcher_daily = data_processor.calculate_cumulative_pitcher_stats(df_pitcher_daily)\n",
    "\n",
    "# Apply ballast and calculate final rolling stats\n",
    "print(\"Applying ballast and calculating final rolling stats...\")\n",
    "df_batter_daily_final = data_processor.calculate_ballasted_batter_stats(\n",
    "    df_batter_daily,\n",
    "    lg_avgs=config.LEAGUE_AVG_RATES,\n",
    "    ballast_weights=config.BALLAST_WEIGHTS\n",
    ")\n",
    "\n",
    "df_pitcher_daily_final = data_processor.calculate_ballasted_pitcher_stats(\n",
    "    df_pitcher_daily,\n",
    "    lg_avgs=config.LEAGUE_AVG_RATES,\n",
    "    ballast_weights=config.BALLAST_WEIGHTS\n",
    ")\n",
    "\n",
    "print(f\"Processed batter stats shape: {df_batter_daily_final.shape}\")\n",
    "print(f\"Processed pitcher stats shape: {df_pitcher_daily_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9d1191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 3: Joining Stats Back to Main DataFrame ===\n",
      "Batter columns to join: ['batter_avg_daily_input', 'batter_k_pct_daily_input', 'batter_bb_pct_daily_input', 'batter_hbp_pct_daily_input', 'batter_1b_pct_daily_input', 'batter_2b_pct_daily_input', 'batter_3b_pct_daily_input', 'batter_hr_pct_daily_input', 'batter_non_k_out_pct_daily_input']\n",
      "Pitcher columns to join: ['pitcher_avg_a_daily_input', 'pitcher_k_pct_a_daily_input', 'pitcher_bb_pct_a_daily_input', 'pitcher_hbp_pct_a_daily_input', 'pitcher_1b_pct_a_daily_input', 'pitcher_2b_pct_a_daily_input', 'pitcher_3b_pct_a_daily_input', 'pitcher_hr_pct_a_daily_input', 'pitcher_non_k_out_pct_a_daily_input']\n",
      "Joining daily stats back to original dataframe...\n",
      "Final joined dataframe shape: (6602, 59)\n",
      "Final columns: ['game_pk', 'at_bat_number', 'pitch_number', 'batter', 'pitcher', 'events', 'stand', 'p_throws', 'inning_topbot', 'home_team', 'away_team', 'game_date', 'game_type', 'bb_type', 'balls', 'strikes', 'outs_when_up', 'inning', 'game_year', 'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6', 'fielder_7', 'fielder_8', 'fielder_9', 'pa_outcome_category', 'is_pa', 'is_ab', 'is_hit', 'is_k', 'is_bb', 'is_hbp', 'is_1b', 'is_2b', 'is_3b', 'is_hr', 'is_out', 'batter_avg_daily_input', 'batter_k_pct_daily_input', 'batter_bb_pct_daily_input', 'batter_hbp_pct_daily_input', 'batter_1b_pct_daily_input', 'batter_2b_pct_daily_input', 'batter_3b_pct_daily_input', 'batter_hr_pct_daily_input', 'batter_non_k_out_pct_daily_input', 'pitcher_avg_a_daily_input', 'pitcher_k_pct_a_daily_input', 'pitcher_bb_pct_a_daily_input', 'pitcher_hbp_pct_a_daily_input', 'pitcher_1b_pct_a_daily_input', 'pitcher_2b_pct_a_daily_input', 'pitcher_3b_pct_a_daily_input', 'pitcher_hr_pct_a_daily_input', 'pitcher_non_k_out_pct_a_daily_input', 'is_platoon_adv', 'is_batter_home']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Join the stats back to the main dataframe\n",
    "print(\"\\n=== Step 3: Joining Stats Back to Main DataFrame ===\")\n",
    "\n",
    "# Get relevant columns\n",
    "batter_cols = data_processor.get_cols_to_join(df_batter_daily_final, \"batter\")\n",
    "pitcher_cols = data_processor.get_cols_to_join(df_pitcher_daily_final, \"pitcher\")\n",
    "\n",
    "print(f\"Batter columns to join: {batter_cols}\")\n",
    "print(f\"Pitcher columns to join: {pitcher_cols}\")\n",
    "\n",
    "# Filter dataframes to only include relevant columns\n",
    "batter_stats_to_join = data_processor.select_subset_of_cols(\n",
    "    df_batter_daily_final, \"batter\", batter_cols\n",
    ")\n",
    "pitcher_stats_to_join = data_processor.select_subset_of_cols(\n",
    "    df_pitcher_daily_final, \"pitcher\", pitcher_cols\n",
    ")\n",
    "\n",
    "# Join everything together\n",
    "print(\"Joining daily stats back to original dataframe...\")\n",
    "main_df = data_processor.join_together_final_df(\n",
    "    df_historical, \n",
    "    batter_stats_to_join, \n",
    "    pitcher_stats_to_join\n",
    ")\n",
    "\n",
    "print(f\"Final joined dataframe shape: {main_df.shape}\")\n",
    "print(f\"Final columns: {main_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e040f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 10:30:26,670 - INFO - storage - Attempting to load DataFrame from: ..\\clean_data\\park_factors.parquet\n",
      "2025-06-03 10:30:26,679 - INFO - storage - Successfully loaded DataFrame from ..\\clean_data\\park_factors.parquet\n",
      "2025-06-03 10:30:26,680 - INFO - storage - Attempting to load DataFrame from: ..\\clean_data\\defensive_stats.parquet\n",
      "2025-06-03 10:30:26,689 - INFO - storage - Successfully loaded DataFrame from ..\\clean_data\\defensive_stats.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 4: Loading Context Data ===\n",
      "Park factors shape: (245, 6)\n",
      "Defensive stats shape: (1305, 7)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load additional context data\n",
    "print(\"\\n=== Step 4: Loading Context Data ===\")\n",
    "\n",
    "# Load park factors and defensive stats\n",
    "try:\n",
    "    park_factors_df = storage.load_dataframe(\"park_factors.parquet\")\n",
    "    player_defense_df = storage.load_dataframe(\"defensive_stats.parquet\")\n",
    "    \n",
    "    if park_factors_df is None or player_defense_df is None:\n",
    "        print(\"Warning: Park factors or defensive stats not found. Using defaults.\")\n",
    "        # Create minimal context data\n",
    "        park_factors_df = pl.DataFrame({\n",
    "            \"venue_id\": [1],\n",
    "            \"year\": [2024],\n",
    "            \"park_factor\": [100.0]\n",
    "        })\n",
    "        player_defense_df = pl.DataFrame({\n",
    "            \"player_id\": [1],\n",
    "            \"year\": [2024],\n",
    "            \"cumulative_oaa_prior\": [0.0]\n",
    "        })\n",
    "    \n",
    "    print(f\"Park factors shape: {park_factors_df.shape}\")\n",
    "    print(f\"Defensive stats shape: {player_defense_df.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading context data: {e}\")\n",
    "    print(\"Creating default context data...\")\n",
    "    \n",
    "    # Create minimal context data\n",
    "    park_factors_df = pl.DataFrame({\n",
    "        \"venue_id\": [1],\n",
    "        \"year\": [2024], \n",
    "        \"park_factor\": [100.0]\n",
    "    })\n",
    "    player_defense_df = pl.DataFrame({\n",
    "        \"player_id\": [1],\n",
    "        \"year\": [2024],\n",
    "        \"cumulative_oaa_prior\": [0.0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed92ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 5: Extracting Features for Scaler ===\n",
      "Filtering for complete records...\n",
      "Available predictor columns (18): ['is_platoon_adv', 'is_batter_home', 'pitcher_k_pct_a_daily_input', 'pitcher_bb_pct_a_daily_input', 'pitcher_hbp_pct_a_daily_input', 'pitcher_1b_pct_a_daily_input', 'pitcher_2b_pct_a_daily_input', 'pitcher_3b_pct_a_daily_input', 'pitcher_hr_pct_a_daily_input', 'pitcher_non_k_out_pct_a_daily_input', 'batter_k_pct_daily_input', 'batter_bb_pct_daily_input', 'batter_hbp_pct_daily_input', 'batter_1b_pct_daily_input', 'batter_2b_pct_daily_input', 'batter_3b_pct_daily_input', 'batter_hr_pct_daily_input', 'batter_non_k_out_pct_daily_input']\n",
      "Missing predictor columns (2): ['team_defense_oaa_input', 'park_factor_input']\n",
      "Complete records: 6602 out of 6602\n",
      "Available continuous columns for scaling: ['pitcher_k_pct_a_daily_input', 'pitcher_bb_pct_a_daily_input', 'pitcher_hbp_pct_a_daily_input', 'pitcher_1b_pct_a_daily_input', 'pitcher_2b_pct_a_daily_input', 'pitcher_3b_pct_a_daily_input', 'pitcher_hr_pct_a_daily_input', 'pitcher_non_k_out_pct_a_daily_input', 'batter_k_pct_daily_input', 'batter_bb_pct_daily_input', 'batter_hbp_pct_daily_input', 'batter_1b_pct_daily_input', 'batter_2b_pct_daily_input', 'batter_3b_pct_daily_input', 'batter_hr_pct_daily_input', 'batter_non_k_out_pct_daily_input']\n",
      "Continuous data shape for scaling: (6602, 16)\n",
      "Sample statistics:\n",
      "       pitcher_k_pct_a_daily_input  pitcher_bb_pct_a_daily_input  \\\n",
      "count                  6602.000000                   6602.000000   \n",
      "mean                      0.227490                      0.081147   \n",
      "std                       0.019573                      0.005192   \n",
      "min                       0.157412                      0.062118   \n",
      "25%                       0.214098                      0.078261   \n",
      "50%                       0.226012                      0.080071   \n",
      "75%                       0.239169                      0.084162   \n",
      "max                       0.301691                      0.101287   \n",
      "\n",
      "       pitcher_hbp_pct_a_daily_input  pitcher_1b_pct_a_daily_input  \\\n",
      "count                    6602.000000                   6602.000000   \n",
      "mean                        0.011468                      0.140163   \n",
      "std                         0.000595                      0.001800   \n",
      "min                         0.010241                      0.133170   \n",
      "25%                         0.011245                      0.139178   \n",
      "50%                         0.011331                      0.140008   \n",
      "75%                         0.011402                      0.141096   \n",
      "max                         0.015232                      0.150894   \n",
      "\n",
      "       pitcher_2b_pct_a_daily_input  pitcher_3b_pct_a_daily_input  \\\n",
      "count                   6602.000000                   6602.000000   \n",
      "mean                       0.043391                      0.003587   \n",
      "std                        0.000481                      0.000156   \n",
      "min                        0.041461                      0.003405   \n",
      "25%                        0.043165                      0.003550   \n",
      "50%                        0.043314                      0.003566   \n",
      "75%                        0.043611                      0.003576   \n",
      "max                        0.046848                      0.004923   \n",
      "\n",
      "       pitcher_hr_pct_a_daily_input  pitcher_non_k_out_pct_a_daily_input  \\\n",
      "count                   6602.000000                          6602.000000   \n",
      "mean                       0.030779                             0.461976   \n",
      "std                        0.000528                             0.019052   \n",
      "min                        0.029033                             0.396229   \n",
      "25%                        0.030538                             0.449719   \n",
      "50%                        0.030677                             0.463004   \n",
      "75%                        0.030770                             0.474420   \n",
      "max                        0.034932                             0.528869   \n",
      "\n",
      "       batter_k_pct_daily_input  batter_bb_pct_daily_input  \\\n",
      "count               6602.000000                6602.000000   \n",
      "mean                   0.225964                   0.080904   \n",
      "std                    0.019069                   0.007478   \n",
      "min                    0.165716                   0.066068   \n",
      "25%                    0.214913                   0.076391   \n",
      "50%                    0.225483                   0.078855   \n",
      "75%                    0.236726                   0.084204   \n",
      "max                    0.316034                   0.130403   \n",
      "\n",
      "       batter_hbp_pct_daily_input  batter_1b_pct_daily_input  \\\n",
      "count                 6602.000000                6602.000000   \n",
      "mean                     0.011467                   0.140381   \n",
      "std                      0.001462                   0.003725   \n",
      "min                      0.010049                   0.129089   \n",
      "25%                      0.010798                   0.137957   \n",
      "50%                      0.011103                   0.139808   \n",
      "75%                      0.011285                   0.142685   \n",
      "max                      0.026176                   0.159688   \n",
      "\n",
      "       batter_2b_pct_daily_input  batter_3b_pct_daily_input  \\\n",
      "count                6602.000000                6602.000000   \n",
      "mean                    0.043479                   0.003596   \n",
      "std                     0.000438                   0.000137   \n",
      "min                     0.042715                   0.003514   \n",
      "25%                     0.043220                   0.003553   \n",
      "50%                     0.043355                   0.003568   \n",
      "75%                     0.043760                   0.003579   \n",
      "max                     0.045899                   0.004203   \n",
      "\n",
      "       batter_hr_pct_daily_input  batter_non_k_out_pct_daily_input  \n",
      "count                6602.000000                       6602.000000  \n",
      "mean                    0.030661                          0.463548  \n",
      "std                     0.003150                          0.018765  \n",
      "min                     0.025915                          0.388234  \n",
      "25%                     0.028763                          0.452911  \n",
      "50%                     0.029913                          0.463993  \n",
      "75%                     0.031649                          0.474988  \n",
      "max                     0.048861                          0.528708  \n"
     ]
    }
   ],
   "source": [
    "# Step 5: Extract features for scaling\n",
    "print(\"\\n=== Step 5: Extracting Features for Scaler ===\")\n",
    "\n",
    "# Filter for complete records (no nulls in predictor columns)\n",
    "print(\"Filtering for complete records...\")\n",
    "\n",
    "# Check which predictor columns exist in the dataframe\n",
    "available_predictors = [col for col in config.PREDICTOR_COLS if col in main_df.columns]\n",
    "missing_predictors = [col for col in config.PREDICTOR_COLS if col not in main_df.columns]\n",
    "\n",
    "print(f\"Available predictor columns ({len(available_predictors)}): {available_predictors}\")\n",
    "if missing_predictors:\n",
    "    print(f\"Missing predictor columns ({len(missing_predictors)}): {missing_predictors}\")\n",
    "\n",
    "# Filter for non-null values in available predictors\n",
    "complete_records = main_df.filter(\n",
    "    pl.all_horizontal([pl.col(col).is_not_null() for col in available_predictors])\n",
    ")\n",
    "\n",
    "print(f\"Complete records: {complete_records.shape[0]} out of {main_df.shape[0]}\")\n",
    "\n",
    "# Extract continuous features that need scaling\n",
    "continuous_cols_available = [col for col in config.CONTINUOUS_COLS if col in complete_records.columns]\n",
    "print(f\"Available continuous columns for scaling: {continuous_cols_available}\")\n",
    "\n",
    "if not continuous_cols_available:\n",
    "    raise ValueError(\"No continuous columns available for scaling!\")\n",
    "\n",
    "# Convert to pandas for sklearn compatibility\n",
    "continuous_data = complete_records.select(continuous_cols_available).to_pandas()\n",
    "\n",
    "print(f\"Continuous data shape for scaling: {continuous_data.shape}\")\n",
    "print(f\"Sample statistics:\")\n",
    "print(continuous_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f1d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 6: Creating and Fitting Scaler ===\n",
      "Fitting scaler on continuous features...\n",
      "Scaler fitted on 16 features\n",
      "Feature names: ['pitcher_k_pct_a_daily_input', 'pitcher_bb_pct_a_daily_input', 'pitcher_hbp_pct_a_daily_input', 'pitcher_1b_pct_a_daily_input', 'pitcher_2b_pct_a_daily_input', 'pitcher_3b_pct_a_daily_input', 'pitcher_hr_pct_a_daily_input', 'pitcher_non_k_out_pct_a_daily_input', 'batter_k_pct_daily_input', 'batter_bb_pct_daily_input', 'batter_hbp_pct_daily_input', 'batter_1b_pct_daily_input', 'batter_2b_pct_daily_input', 'batter_3b_pct_daily_input', 'batter_hr_pct_daily_input', 'batter_non_k_out_pct_daily_input']\n",
      "Scaler means: [0.22749002 0.0811467  0.01146754 0.14016253 0.04339129 0.00358652\n",
      " 0.03077919 0.46197621 0.22596394 0.08090378 0.01146677 0.14038083\n",
      " 0.04347932 0.00359581 0.03066114 0.4635484 ]\n",
      "Scaler scales: [0.01957183 0.00519156 0.00059544 0.00179956 0.00048111 0.00015615\n",
      " 0.00052788 0.01905089 0.01906724 0.00747773 0.00146211 0.00372492\n",
      " 0.00043823 0.00013743 0.00314968 0.01876348]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create and fit the scaler\n",
    "print(\"\\n=== Step 6: Creating and Fitting Scaler ===\")\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the continuous features\n",
    "print(\"Fitting scaler on continuous features...\")\n",
    "scaler.fit(continuous_data)\n",
    "\n",
    "print(f\"Scaler fitted on {scaler.n_features_in_} features\")\n",
    "print(f\"Feature names: {continuous_cols_available}\")\n",
    "print(f\"Scaler means: {scaler.mean_}\")\n",
    "print(f\"Scaler scales: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aadead6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 7: Validating Scaler ===\n",
      "Original sample mean: [0.22422898 0.08150506 0.01145745 0.14002373 0.04339922 0.00360153\n",
      " 0.03084647 0.46493756 0.23124658 0.08164525 0.01152847 0.13988365\n",
      " 0.04347314 0.00359445 0.03039332 0.45823515]\n",
      "Original sample std: [0.01857172 0.00517772 0.00054216 0.00170021 0.00046254 0.0001743\n",
      " 0.00050426 0.01827484 0.02033855 0.00935148 0.00151079 0.00330594\n",
      " 0.0004698  0.00013451 0.00273265 0.02126235]\n",
      "Scaled sample mean: [-0.16661926  0.06902758 -0.01695018 -0.07713022  0.01647445  0.09618859\n",
      "  0.12746368  0.15544399  0.27705314  0.09915699  0.04219674 -0.13347466\n",
      " -0.01411788 -0.0099025  -0.0850315  -0.28316982]\n",
      "Scaled sample std: [0.94414428 0.9923364  0.90594937 0.94005678 0.9565816  1.11065041\n",
      " 0.95047889 0.95445625 1.06132847 1.24430849 1.02811679 0.88307174\n",
      " 1.06665608 0.97383187 0.8632451  1.12749713]\n",
      "⚠️ Scaler validation warning: scaled data doesn't have expected mean=0, std=1\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Validate the scaler\n",
    "print(\"\\n=== Step 7: Validating Scaler ===\")\n",
    "\n",
    "# Transform a sample to verify it works\n",
    "sample_data = continuous_data.head(100)\n",
    "scaled_sample = scaler.transform(sample_data)\n",
    "\n",
    "print(f\"Original sample mean: {sample_data.mean().values}\")\n",
    "print(f\"Original sample std: {sample_data.std().values}\")\n",
    "print(f\"Scaled sample mean: {scaled_sample.mean(axis=0)}\")\n",
    "print(f\"Scaled sample std: {scaled_sample.std(axis=0)}\")\n",
    "\n",
    "# Check that scaled data has mean ~0 and std ~1\n",
    "if np.allclose(scaled_sample.mean(axis=0), 0, atol=0.1) and np.allclose(scaled_sample.std(axis=0), 1, atol=0.1):\n",
    "    print(\"✅ Scaler validation passed!\")\n",
    "else:\n",
    "    print(\"⚠️ Scaler validation warning: scaled data doesn't have expected mean=0, std=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42176722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Save the scaler\n",
    "print(\"\\n=== Step 8: Saving Scaler ===\")\n",
    "\n",
    "# Create output path\n",
    "output_path = \"baseball_simulator/pa_outcome_scaler.joblib\"\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, output_path)\n",
    "print(f\"✅ Scaler saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Test loading the saved scaler\n",
    "print(\"\\n=== Step 9: Testing Saved Scaler ===\")\n",
    "\n",
    "# Load the scaler back and test it\n",
    "loaded_scaler = joblib.load(output_path)\n",
    "test_transform = loaded_scaler.transform(sample_data.head(5))\n",
    "\n",
    "print(f\"✅ Successfully loaded and tested scaler from {output_path}\")\n",
    "print(f\"Test transform shape: {test_transform.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Summary\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"✅ Successfully created pa_outcome_scaler.joblib\")\n",
    "print(f\"📍 Location: {output_path}\")\n",
    "print(f\"📊 Trained on {continuous_data.shape[0]} samples\")\n",
    "print(f\"🔢 Features ({len(continuous_cols_available)}): {continuous_cols_available}\")\n",
    "print(f\"📈 Feature means: {scaler.mean_.round(4)}\")\n",
    "print(f\"📉 Feature scales: {scaler.scale_.round(4)}\")\n",
    "\n",
    "print(\"\\n🎉 Scaler creation process completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

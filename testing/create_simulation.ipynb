{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjSfOmFmHD6kqQAwgrhcW/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zENCOKpPiXlh","executionInfo":{"status":"ok","timestamp":1745108337929,"user_tz":240,"elapsed":535,"user":{"displayName":"Sam","userId":"02456008665656849434"}},"outputId":"0dd4f4ad-0c80-4b3e-a185-d0062596fc13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pymc as pm\n","import arviz as az\n","import numpy as np\n","import polars as pl # Or pandas\n","import joblib\n","import random\n","import pytensor.tensor as pt # For softmax if calculating manually\n","import numpy as np\n","import random\n","import polars as pl # Assuming you might use Polars Series sometimes\n","import pandas as pd # For DataFrame creation in helper\n","from sklearn.preprocessing import StandardScaler # Needed for helper\n","import joblib # Needed for helper\n","import arviz as az # Needed for helper\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","pl.Config.set_tbl_cols(200)\n","pl.Config.set_tbl_rows(200)\n","\n","FILE_PATH = '/content/drive/My Drive/Betting Models/mlb/hits_model/'"]},{"cell_type":"markdown","source":["## Load Model & Scaler"],"metadata":{"id":"_HD1yXlblFaU"}},{"cell_type":"code","source":["# Load InferenceData (replace with your path)\n","idata = az.from_netcdf(f\"{FILE_PATH}multi_outcome_model.nc\")\n","\n","# Load the scaler used during training (replace with your path)\n","scaler_filename = f\"{FILE_PATH}pa_outcome_scaler.joblib\"\n","scaler = joblib.load(scaler_filename)\n","\n","# Define outcome category mapping (same as used in training)\n","outcome_labels = {\n","    0: \"Out_In_Play\", 1: \"Single\", 2: \"Double\", 3: \"Triple\", 4: \"HomeRun\",\n","    5: \"Strikeout\", 6: \"Walk\", 7: \"HBP\"\n","    # Add/modify based on your actual categories\n","}\n","n_categories = len(outcome_labels) # Should match model dimension\n","\n","\n","# List ALL predictor columns you calculated and joined\n","# Make sure these names exactly match your DataFrame columns\n","predictor_cols = [\n","    'is_platoon_adv',\n","    'is_batter_home',\n","    # Pitcher Stats\n","    # 'pitcher_avg_a_daily_input',\n","    'pitcher_k_pct_a_daily_input',\n","    'pitcher_bb_pct_a_daily_input',\n","    'pitcher_hbp_pct_a_daily_input',\n","    'pitcher_1b_pct_a_daily_input',\n","    'pitcher_2b_pct_a_daily_input',\n","    'pitcher_3b_pct_a_daily_input',\n","    'pitcher_hr_pct_a_daily_input',\n","    'pitcher_non_k_out_pct_a_daily_input',\n","    # Add other pitcher rate inputs here (HBP%, 1B%, 2B%, 3B%, HR%) if calculated\n","    # Batter Stats\n","    # 'batter_avg_daily_input',\n","    'batter_k_pct_daily_input',\n","    'batter_bb_pct_daily_input',\n","    'batter_hbp_pct_daily_input',\n","    'batter_1b_pct_daily_input',\n","    'batter_2b_pct_daily_input',\n","    'batter_3b_pct_daily_input',\n","    'batter_hr_pct_daily_input',\n","    'batter_non_k_out_pct_daily_input',\n","    # Add other batter rate inputs here (HBP%, 1B%, 2B%, 3B%, HR%) if calculated\n","    # Context Stats\n","    'team_defense_oaa_input',\n","    'park_factor_input',\n","]\n","\n","# Identify continuous columns needing scaling vs categorical (like platoon)\n","continuous_cols = [\n","    # 'pitcher_avg_a_daily_input',\n","    'pitcher_k_pct_a_daily_input',\n","    'pitcher_bb_pct_a_daily_input',\n","    'pitcher_hbp_pct_a_daily_input',\n","    'pitcher_1b_pct_a_daily_input',\n","    'pitcher_2b_pct_a_daily_input',\n","    'pitcher_3b_pct_a_daily_input',\n","    'pitcher_hr_pct_a_daily_input',\n","    'pitcher_non_k_out_pct_a_daily_input',\n","    # 'batter_avg_daily_input',\n","    'batter_k_pct_daily_input',\n","    'batter_bb_pct_daily_input',\n","    'batter_hbp_pct_daily_input',\n","    'batter_1b_pct_daily_input',\n","    'batter_2b_pct_daily_input',\n","    'batter_3b_pct_daily_input',\n","    'batter_hr_pct_daily_input',\n","    'batter_non_k_out_pct_daily_input',\n","    'team_defense_oaa_input',\n","    'park_factor_input',\n","    # Add other continuous rate inputs here\n","]\n","categorical_cols = ['is_platoon_adv', 'is_batter_home']"],"metadata":{"id":"0cLRePwplAlu","executionInfo":{"status":"ok","timestamp":1745108342672,"user_tz":240,"elapsed":2322,"user":{"displayName":"Sam","userId":"02456008665656849434"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Create Function to Predict Probabilities"],"metadata":{"id":"uyaKZuPSkSRf"}},{"cell_type":"code","source":["# --- Helper Function: Predict PA Outcome Probabilities (Using Mean Posterior) ---\n","# (Copied from previous response - ensure this is available)\n","def predict_pa_outcome_probs(pa_inputs_dict, idata, scaler, predictor_cols, continuous_cols, categorical_cols, n_categories):\n","    \"\"\"\n","    Predicts outcome probabilities for a single PA using MEAN model posterior parameters.\n","    # ... (rest of the function code as provided in the previous response) ...\n","    \"\"\"\n","    # 1. Prepare Input Data into correct order\n","    try:\n","        input_list = [pa_inputs_dict[col] for col in predictor_cols]\n","        input_array = np.array(input_list).reshape(1, -1) # Reshape to 2D array (1 row)\n","    except KeyError as e:\n","        print(f\"Error: Missing key {e} in pa_inputs_dict\")\n","        print(f\"Required keys: {predictor_cols}\")\n","        raise\n","\n","    # Use Pandas for easier column selection based on names for scaling\n","    # Ensure predictor_cols contains only the feature columns\n","    feature_df = pd.DataFrame(input_array, columns=predictor_cols)\n","\n","    # 2. Scale Continuous Features\n","    # Ensure continuous_cols only contains columns present in feature_df\n","    valid_continuous_cols = [col for col in continuous_cols if col in feature_df.columns]\n","    continuous_data = feature_df[valid_continuous_cols].values\n","    try:\n","        scaled_continuous_data = scaler.transform(continuous_data) # Use transform, NOT fit_transform\n","    except Exception as e:\n","        print(f\"Error scaling data: {e}\")\n","        print(f\"Input data shape for scaling: {continuous_data.shape}\")\n","        print(f\"Scaler expects {scaler.n_features_in_} features.\")\n","        # Make sure continuous_cols list matches scaler's fitted columns IN ORDER\n","        raise\n","\n","    # 3. Combine Features\n","    # Ensure categorical_cols only contains columns present in feature_df\n","    valid_categorical_cols = [col for col in categorical_cols if col in feature_df.columns]\n","    categorical_data = feature_df[valid_categorical_cols].values\n","    try:\n","      X_new = np.concatenate([scaled_continuous_data, categorical_data], axis=1)\n","    except ValueError as e:\n","        print(f\"Error concatenating features: {e}\")\n","        print(f\"Scaled continuous shape: {scaled_continuous_data.shape}\")\n","        print(f\"Categorical shape: {categorical_data.shape}\")\n","        raise\n","\n","    n_predictors = X_new.shape[1] # Get number of predictors from the combined array\n","\n","    # 4. Use Mean Posterior Parameters\n","    try:\n","        # Ensure 'intercepts' and 'betas' exist and have correct structure after potential reshaping\n","        # This assumes intercepts/betas in idata already account for the reference category\n","        mean_intercepts = idata.posterior[\"intercepts\"].mean(dim=(\"chain\", \"draw\")).values\n","        mean_betas = idata.posterior[\"betas\"].mean(dim=(\"chain\", \"draw\")).values\n","    except Exception as e:\n","        print(f\"Error accessing posterior samples in idata: {e}\")\n","        print(\"Make sure 'intercepts' and 'betas' were saved correctly in idata.\")\n","        raise\n","\n","    # Check shapes and adjust if necessary (if idata stored offsets)\n","    expected_intercept_shape = (n_categories,)\n","    expected_beta_shape = (n_predictors, n_categories)\n","\n","    # --- This logic assumes idata stored the FULL parameters ---\n","    # --- If idata stored offsets, you'd reconstruct here as done previously ---\n","    if mean_intercepts.shape != expected_intercept_shape:\n","         raise ValueError(f\"Mean intercepts shape mismatch. Expected {expected_intercept_shape}, got {mean_intercepts.shape}. Reconstruction might be needed.\")\n","    if mean_betas.shape != expected_beta_shape:\n","         raise ValueError(f\"Mean betas shape mismatch. Expected {expected_beta_shape}, got {mean_betas.shape}. Reconstruction might be needed.\")\n","\n","    # 5. Calculate Linear Predictor (mu)\n","    mu_mean = mean_intercepts + X_new @ mean_betas # Shape (1, n_categories)\n","\n","    # 6. Apply Softmax\n","    exp_mu_mean = np.exp(mu_mean - np.max(mu_mean, axis=1, keepdims=True))\n","    p_vector_mean = exp_mu_mean / np.sum(exp_mu_mean, axis=1, keepdims=True)\n","\n","    # Ensure probabilities sum roughly to 1\n","    if not np.isclose(np.sum(p_vector_mean), 1.0):\n","        print(f\"Warning: Probabilities do not sum to 1: {np.sum(p_vector_mean)}\")\n","        p_vector_mean = p_vector_mean / np.sum(p_vector_mean) # Normalize\n","\n","    return p_vector_mean.flatten()\n","\n","\n","\n","\n"],"metadata":{"id":"3sNG9vQkrxbh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Helper Function: Predict PA Outcome Probabilities (Using Mean Posterior) ---\n","# Needs idata, scaler, predictor_cols, etc., defined in the main scope or passed\n","# This version uses the mean of the posterior parameters for simplicity\n","\n","def predict_pa_outcome_probs(pa_inputs_dict, idata, scaler, predictor_cols, continuous_cols, categorical_cols, n_categories):\n","    \"\"\"\n","    Predicts outcome probabilities for a single PA using MEAN model posterior parameters.\n","\n","    Args:\n","        pa_inputs_dict (dict): Dict with predictor names as keys and single values.\n","        idata (arviz.InferenceData): Fitted model inference data.\n","        scaler (sklearn.preprocessing.StandardScaler): Fitted scaler object.\n","        predictor_cols (list): List of all predictor column names in order.\n","        continuous_cols (list): List of continuous predictor columns for scaling.\n","        categorical_cols (list): List of categorical/binary columns.\n","        n_categories (int): Number of outcome categories.\n","\n","    Returns:\n","        np.ndarray: A probability vector (sums to 1) for the PA outcomes. Shape: (n_categories,)\n","    \"\"\"\n","    # 1. Prepare Input Data into correct order\n","    try:\n","        input_list = [pa_inputs_dict[col] for col in predictor_cols]\n","        input_array = np.array(input_list).reshape(1, -1) # Reshape to 2D array (1 row)\n","    except KeyError as e:\n","        print(f\"Error: Missing key {e} in pa_inputs_dict\")\n","        print(f\"Required keys: {predictor_cols}\")\n","        raise\n","\n","    # Use Pandas for easier column selection based on names for scaling\n","    input_df = pd.DataFrame(input_array, columns=predictor_cols)\n","\n","    # 2. Scale Continuous Features\n","    continuous_data = input_df[continuous_cols].values\n","    try:\n","        scaled_continuous_data = scaler.transform(continuous_data) # Use transform, NOT fit_transform\n","    except Exception as e:\n","        print(f\"Error scaling data: {e}\")\n","        print(f\"Input data shape for scaling: {continuous_data.shape}\")\n","        print(f\"Scaler expects {scaler.n_features_in_} features.\")\n","        raise\n","\n","    # 3. Combine Features\n","    categorical_data = input_df[categorical_cols].values\n","    X_new = np.concatenate([scaled_continuous_data, categorical_data], axis=1)\n","    n_predictors = X_new.shape[1]\n","\n","\n","    # 4. Use Mean Posterior Parameters\n","    try:\n","        mean_intercepts = idata.posterior[\"intercepts\"].mean(dim=(\"chain\", \"draw\")).values\n","        mean_betas = idata.posterior[\"betas\"].mean(dim=(\"chain\", \"draw\")).values\n","    except Exception as e:\n","        print(f\"Error accessing posterior samples in idata: {e}\")\n","        print(\"Make sure 'intercepts' and 'betas' were saved correctly.\")\n","        raise\n","\n","    # Check shapes\n","    expected_intercept_shape = (n_categories,)\n","    expected_beta_shape = (n_predictors, n_categories)\n","\n","    if mean_intercepts.shape != expected_intercept_shape:\n","         print(f\"Warning: Mean intercepts shape mismatch. Expected {expected_intercept_shape}, got {mean_intercepts.shape}\")\n","         # Attempt to reshape or handle based on how reference category was added\n","         # This assumes reference category (all zeros) was added as the last one\n","         if mean_intercepts.shape == (n_categories - 1,):\n","              mean_intercepts = np.concatenate([mean_intercepts, [0.0]])\n","         else:\n","              raise ValueError(\"Cannot resolve intercept shape mismatch.\")\n","\n","\n","    if mean_betas.shape != expected_beta_shape:\n","        print(f\"Warning: Mean betas shape mismatch. Expected {expected_beta_shape}, got {mean_betas.shape}\")\n","        # Attempt to reshape or handle based on how reference category was added\n","        if mean_betas.shape == (n_predictors, n_categories - 1):\n","             ref_betas = np.zeros((n_predictors, 1))\n","             mean_betas = np.concatenate([mean_betas, ref_betas], axis=1)\n","        else:\n","             raise ValueError(\"Cannot resolve beta shape mismatch.\")\n","\n","\n","    # 5. Calculate Linear Predictor (mu)\n","    mu_mean = mean_intercepts + X_new @ mean_betas # Shape (1, n_categories)\n","\n","    # 6. Apply Softmax (manual implementation for stability)\n","    exp_mu_mean = np.exp(mu_mean - np.max(mu_mean, axis=1, keepdims=True))\n","    p_vector_mean = exp_mu_mean / np.sum(exp_mu_mean, axis=1, keepdims=True)\n","\n","    # Ensure probabilities sum roughly to 1\n","    if not np.isclose(np.sum(p_vector_mean), 1.0):\n","        print(f\"Warning: Probabilities do not sum to 1: {np.sum(p_vector_mean)}\")\n","        # Normalize as fallback\n","        p_vector_mean = p_vector_mean / np.sum(p_vector_mean)\n","\n","\n","    return p_vector_mean.flatten() # Return the single probability vector"],"metadata":{"id":"n-5PsnqBcwyw","executionInfo":{"status":"ok","timestamp":1745108345305,"user_tz":240,"elapsed":5,"user":{"displayName":"Sam","userId":"02456008665656849434"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Create Function to Simulate One Inning"],"metadata":{"id":"Hv0_Rmm1kVqh"}},{"cell_type":"code","source":["# --- Core Inning Simulation Function (Includes GIDP etc.) ---\n","# (Copied and refined from previous response)\n","def simulate_single_inning(inning_num, is_top_inning, lineup, start_batter_idx,\n","                           pitcher_inputs, game_context, # game_context has park, BOTH team defenses\n","                           idata, scaler, outcome_labels,\n","                           predictor_cols, continuous_cols, categorical_cols,\n","                           n_categories, league_avg_rates):\n","    \"\"\"Simulates a single half-inning with realistic base running.\"\"\"\n","    outs = 0\n","    hits = 0\n","    runs = 0\n","    walks = 0 # Added walk tracking\n","    bases = [0, 0, 0] # 0=empty, 1=runner present\n","    current_batter_idx = start_batter_idx\n","    lineup_len = len(lineup)\n","\n","    # Determine fielding team's defense rating from game_context\n","    if is_top_inning: # Away team batting, Home team fielding\n","        fielding_team_defense_rating = game_context['home_team_defense_rating']\n","        is_batter_home = 0\n","    else: # Home team batting, Away team fielding\n","        fielding_team_defense_rating = game_context['away_team_defense_rating']\n","        is_batter_home = 1\n","\n","    inning_context_pa = {\n","        'park_factor_input': game_context['park_factor_input'],\n","        'team_defense_oaa_input': fielding_team_defense_rating,\n","        'is_batter_home': is_batter_home\n","    }\n","\n","    while outs < 3:\n","        batter_spot_in_lineup = current_batter_idx % lineup_len\n","        current_batter_inputs = lineup[batter_spot_in_lineup]\n","\n","        try:\n","            batter_stand = current_batter_inputs['stand']\n","            pitcher_throws = pitcher_inputs['p_throws']\n","            is_platoon = 1 if (batter_stand == 'L' and pitcher_throws == 'R') or \\\n","                              (batter_stand == 'R' and pitcher_throws == 'L') else 0\n","        except KeyError as e:\n","             print(f\"Warning: Missing 'stand' or 'p_throws' in inputs: {e}. Assuming no platoon advantage.\")\n","             is_platoon = 0\n","\n","        pa_inputs = {\n","            **current_batter_inputs,\n","            **pitcher_inputs,\n","            **inning_context_pa,\n","            'is_platoon_adv': is_platoon\n","        }\n","        # Remove non-predictor keys if they exist from batter/pitcher inputs\n","        pa_inputs = {k: v for k, v in pa_inputs.items() if k in predictor_cols or k in ['stand', 'p_throws']}\n","\n","\n","        outcome_probs = predict_pa_outcome_probs(\n","            pa_inputs, idata, scaler, predictor_cols,\n","            continuous_cols, categorical_cols, n_categories\n","        )\n","\n","        possible_outcomes = list(outcome_labels.keys())\n","        simulated_outcome_code = np.random.choice(possible_outcomes, p=outcome_probs)\n","        outcome_label = outcome_labels[simulated_outcome_code]\n","\n","        new_bases = list(bases)\n","        runs_this_pa = 0\n","        pa_hit = 0\n","        pa_walk = 0\n","\n","        # Store outs *before* this PA is resolved for GIDP check\n","        outs_before_pa = outs\n","\n","        if outcome_label == \"Strikeout\":\n","            outs += 1\n","        elif outcome_label == \"Walk\":\n","            pa_walk += 1 # Track walk\n","            # Force runner advancement logic (simplified)\n","            if bases[0] == 1:\n","                if bases[1] == 1:\n","                    if bases[2] == 1: runs_this_pa += 1\n","                    new_bases[2] = 1\n","                new_bases[1] = 1\n","            new_bases[0] = 1\n","        elif outcome_label == \"HBP\":\n","             # Force runner advancement logic (same as walk)\n","            if bases[0] == 1:\n","                if bases[1] == 1:\n","                    if bases[2] == 1: runs_this_pa += 1\n","                    new_bases[2] = 1\n","                new_bases[1] = 1\n","            new_bases[0] = 1\n","        elif outcome_label == \"Single\":\n","            pa_hit += 1\n","            # Advance runners (simplified rules + probabilistic 1st->3rd)\n","            runner_3b_scores = (bases[2] == 1)\n","            runner_2b_scores = (bases[1] == 1) # Assume scores from 2nd\n","            runner_1b_to_3rd = False\n","            runner_1b_to_2nd = False\n","\n","            if runner_3b_scores: runs_this_pa += 1\n","            if runner_2b_scores: runs_this_pa += 1\n","\n","            if bases[0] == 1:\n","                if random.random() < league_avg_rates[\"rate_1st_to_3rd_on_single\"]:\n","                    runner_1b_to_3rd = True\n","                else:\n","                    runner_1b_to_2nd = True\n","\n","            # Place runners\n","            new_bases = [0, 0, 0]\n","            if runner_1b_to_3rd: new_bases[2] = 1\n","            elif runner_from_2b_scores == False and bases[1] == 1: new_bases[2] = 1 # R2 holds 3rd if didn't score\n","            if runner_1b_to_2nd: new_bases[1] = 1\n","            new_bases[0] = 1 # Batter to 1st\n","\n","        elif outcome_label == \"Double\":\n","            pa_hit += 1\n","            runner_3b_scores = (bases[2] == 1)\n","            runner_2b_scores = (bases[1] == 1)\n","            runner_1b_scores = False\n","            runner_1b_to_3rd = False\n","\n","            if runner_3b_scores: runs_this_pa += 1\n","            if runner_2b_scores: runs_this_pa += 1\n","            if bases[0] == 1:\n","                if random.random() < league_avg_rates[\"rate_score_from_1st_on_double\"]:\n","                    runner_1b_scores = True\n","                    runs_this_pa += 1\n","                else:\n","                    runner_1b_to_3rd = True\n","\n","            new_bases = [0, 0, 0]\n","            new_bases[1] = 1 # Batter to 2nd\n","            if runner_1b_to_3rd: new_bases[2] = 1\n","\n","        elif outcome_label == \"Triple\":\n","            pa_hit += 1\n","            runs_this_pa += sum(bases) # All runners score\n","            new_bases = [0, 0, 1] # Batter to 3rd\n","\n","        elif outcome_label == \"HomeRun\":\n","            pa_hit += 1\n","            runs_this_pa += 1 + sum(bases)\n","            new_bases = [0, 0, 0]\n","\n","        elif outcome_label == \"Out_In_Play\":\n","            outs += 1\n","            # Check GIDP opportunity (runner on 1st, less than 2 outs *before* this PA)\n","            is_gidp_opportunity = (bases[0] == 1 and outs_before_pa < 2)\n","            # Use adjusted rate directly, as bb_type isn't predicted\n","            adjusted_gidp_rate = league_avg_rates.get(\"gidp_effective_rate\", 0.065) # Use pre-calculated effective rate\n","\n","            if is_gidp_opportunity and random.random() < adjusted_gidp_rate:\n","                if outs < 3: # Ensure DP doesn't add 4th out\n","                   outs += 1 # It's a double play\n","                # Simplified GIDP: batter out, runner forced at 2nd is out, others hold/advance if forced by other runners\n","                runner_3b_holds = (bases[2] == 1)\n","                runner_2b_to_3rd = (bases[1] == 1)\n","                new_bases = [0,0,0] # Batter out, runner from 1st out at 2nd\n","                if runner_2b_to_3rd : new_bases[2] = 1 # Runner from 2nd takes 3rd\n","                if runner_3b_holds and not runner_2b_to_3rd : new_bases[2] = 1 # Runner from 3rd holds if not pushed\n","\n","            else: # Not a GIDP\n","                # Batter is out, advance runners if forced (simplified: 1 base)\n","                runner_3b_holds = (bases[2] == 1)\n","                runner_2b_to_3rd = (bases[1] == 1)\n","                runner_1b_to_2nd = (bases[0] == 1)\n","                new_bases = [0,0,0] # Batter out\n","                if runner_1b_to_2nd : new_bases[1] = 1\n","                if runner_2b_to_3rd : new_bases[2] = 1\n","                if runner_3b_holds and not runner_2b_to_3rd : new_bases[2] = 1\n","\n","        # Update inning totals and base state\n","        runs += runs_this_pa\n","        hits += pa_hit\n","        walks += pa_walk\n","        bases = new_bases\n","\n","        # --- Optional: Secondary Events Logic here ---\n","\n","        # Move to next batter for next loop iteration\n","        current_batter_idx += 1\n","\n","    # Inning Over\n","    return hits, runs, walks, (current_batter_idx % lineup_len)"],"metadata":{"id":"NFvWlwa-kV3W","executionInfo":{"status":"ok","timestamp":1745108352720,"user_tz":240,"elapsed":19,"user":{"displayName":"Sam","userId":"02456008665656849434"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# --- Function to Simulate First 3 Innings ---\n","def simulate_first_three_innings(\n","    home_lineup, away_lineup, home_pitcher_inputs, away_pitcher_inputs,\n","    game_context, # Dict with park_factor_input, home_team_defense_rating, away_team_defense_rating\n","    idata, scaler, outcome_labels, predictor_cols, continuous_cols,\n","    categorical_cols, n_categories, league_avg_rates):\n","    \"\"\"\n","    Simulates the first 3 innings of a game.\n","\n","    Returns:\n","        dict: Results containing hits, runs, walks per team per inning.\n","              Example: {'inning_1': {'away': {'H':1,'R':0,'BB':0}, 'home': {'H':0,'R':0,'BB':1}}, ...}\n","    \"\"\"\n","\n","    results = {}\n","    away_batter_idx = 0\n","    home_batter_idx = 0\n","\n","    for inning in range(1, 4): # Innings 1, 2, 3\n","        inning_results = {'away': {}, 'home': {}}\n","\n","        # --- Top of Inning ---\n","        inning_context_top = {\n","            'park_factor_input': game_context['park_factor_input'],\n","            'team_defense_oaa_input': game_context['home_team_defense_rating'], # Home team defends\n","            'is_batter_home': 0\n","        }\n","        away_hits, away_runs, away_walks, away_batter_idx_next = simulate_single_inning(\n","            inning, True, away_lineup, away_batter_idx, home_pitcher_inputs,\n","            inning_context_top, idata, scaler, outcome_labels,\n","            predictor_cols, continuous_cols, categorical_cols, n_categories, league_avg_rates\n","        )\n","        inning_results['away'] = {'H': away_hits, 'R': away_runs, 'BB': away_walks}\n","        away_batter_idx = away_batter_idx_next # Update for next away inning\n","\n","        # --- Bottom of Inning ---\n","        inning_context_bot = {\n","            'park_factor_input': game_context['park_factor_input'],\n","            'team_defense_oaa_input': game_context['away_team_defense_rating'], # Away team defends\n","            'is_batter_home': 1\n","        }\n","        home_hits, home_runs, home_walks, home_batter_idx_next = simulate_single_inning(\n","            inning, False, home_lineup, home_batter_idx, away_pitcher_inputs,\n","            inning_context_bot, idata, scaler, outcome_labels,\n","            predictor_cols, continuous_cols, categorical_cols, n_categories, league_avg_rates\n","        )\n","        inning_results['home'] = {'H': home_hits, 'R': home_runs, 'BB': home_walks}\n","        home_batter_idx = home_batter_idx_next # Update for next home inning\n","\n","        results[f'inning_{inning}'] = inning_results\n","\n","    return results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"iqG7IEo4vSgK","executionInfo":{"status":"error","timestamp":1745094542681,"user_tz":240,"elapsed":66,"user":{"displayName":"Sam","userId":"02456008665656849434"}},"outputId":"8901bed0-9faa-48c1-b986-85c8a0652283"},"execution_count":3,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"':' expected after dictionary key (<ipython-input-3-ee256b6228c6>, line 6)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-ee256b6228c6>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    batter1_stats = {'batter_avg_daily_input': 0.270, 'batter_k_pct_daily_input': 0.20, ...} # Use projections!\u001b[0m\n\u001b[0m                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m ':' expected after dictionary key\n"]}]},{"cell_type":"markdown","source":["## Run Simulations"],"metadata":{"id":"Yyto_9rZvSNz"}},{"cell_type":"code","source":["#--- Run Multiple Simulations ---\n","num_total_simulations = 10000\n","all_results = []\n","print(f\"Running {num_total_simulations} game simulations...\")\n","for _ in range(num_total_simulations):\n","    sim_result = simulate_first_three_innings(\n","        home_lineup, away_lineup, home_pitcher_inputs, away_pitcher_inputs,\n","        game_context, idata, scaler, outcome_labels, predictor_cols, continuous_cols,\n","        categorical_cols, n_categories, league_avg_rates\n","    )\n","    all_results.append(sim_result)"],"metadata":{"id":"RCfyJQ9FzwV_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import polars as pl\n","import collections # Needed for example data generation\n","import random      # Needed for example data generation\n","import json        # For printing example data\n","\n","# --- Assume final_probabilities dictionary exists ---\n","# (Generated from the analysis code in the previous step that tallied simulation runs)\n","# Example structure:\n","final_probabilities = {\n","  \"inning_1\": {\n","    \"away\": {\n","      \"H\": {\"0\": 0.60, \"1\": 0.25, \"2\": 0.10, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","      \"BB\": {\"0\": 0.70, \"1\": 0.20, \"2\": 0.05, \"3\": 0.02, \"4\": 0.01, \"5+\": 0.02},\n","      \"HR\": {\"0\": 0.90, \"1\": 0.07, \"2\": 0.02, \"3\": 0.01, \"4\": 0.00, \"5+\": 0.00}\n","    },\n","    \"home\": { # Populate example data for home team and other innings\n","      \"H\": {\"0\": 0.55, \"1\": 0.28, \"2\": 0.12, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","      \"BB\": {\"0\": 0.65, \"1\": 0.22, \"2\": 0.07, \"3\": 0.03, \"4\": 0.02, \"5+\": 0.01},\n","      \"HR\": {\"0\": 0.88, \"1\": 0.08, \"2\": 0.02, \"3\": 0.01, \"4\": 0.01, \"5+\": 0.00}\n","    }\n","  },\n","  \"inning_2\": { # Populate example data\n","      \"away\": {\n","          \"H\": {\"0\": 0.62, \"1\": 0.24, \"2\": 0.09, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","          \"BB\": {\"0\": 0.72, \"1\": 0.19, \"2\": 0.05, \"3\": 0.02, \"4\": 0.01, \"5+\": 0.01},\n","          \"HR\": {\"0\": 0.91, \"1\": 0.06, \"2\": 0.02, \"3\": 0.01, \"4\": 0.00, \"5+\": 0.00}\n","        },\n","      \"home\": {\n","          \"H\": {\"0\": 0.57, \"1\": 0.27, \"2\": 0.11, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","          \"BB\": {\"0\": 0.67, \"1\": 0.21, \"2\": 0.07, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","          \"HR\": {\"0\": 0.89, \"1\": 0.07, \"2\": 0.02, \"3\": 0.01, \"4\": 0.01, \"5+\": 0.00}\n","        }\n","  },\n","   \"inning_3\": { # Populate example data\n","      \"away\": {\n","          \"H\": {\"0\": 0.61, \"1\": 0.26, \"2\": 0.08, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","          \"BB\": {\"0\": 0.71, \"1\": 0.20, \"2\": 0.05, \"3\": 0.02, \"4\": 0.01, \"5+\": 0.01},\n","          \"HR\": {\"0\": 0.92, \"1\": 0.05, \"2\": 0.02, \"3\": 0.01, \"4\": 0.00, \"5+\": 0.00}\n","        },\n","      \"home\": {\n","          \"H\": {\"0\": 0.56, \"1\": 0.29, \"2\": 0.10, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","          \"BB\": {\"0\": 0.66, \"1\": 0.23, \"2\": 0.06, \"3\": 0.03, \"4\": 0.01, \"5+\": 0.01},\n","          \"HR\": {\"0\": 0.90, \"1\": 0.07, \"2\": 0.02, \"3\": 0.01, \"4\": 0.00, \"5+\": 0.00}\n","        }\n","   }\n","}\n","# --- End Example Data ---\n","\n","\n","# --- Convert nested dictionary to a list of records ---\n","data_for_df = []\n","for inn_str, teams_data in final_probabilities.items():\n","    # Extract inning number from the key 'inning_X'\n","    try:\n","        inning_num = int(inn_str.split('_')[1])\n","    except (IndexError, ValueError):\n","        print(f\"Warning: Could not parse inning number from key '{inn_str}'. Skipping.\")\n","        continue\n","\n","    for team, stats_data in teams_data.items(): # team is 'away' or 'home'\n","        for stat, bins_data in stats_data.items(): # stat is 'H', 'BB', or 'HR'\n","            for number_bin, probability in bins_data.items(): # number_bin is '0', '1', ..., '5+'\n","                data_for_df.append({\n","                    \"inning\": inning_num,\n","                    \"team\": team,\n","                    \"stat\": stat,\n","                    \"number\": number_bin, # Keep the bin label ('0', '1', ..., '5+')\n","                    \"probability\": probability\n","                })\n","\n","# --- Create Polars DataFrame ---\n","# Define schema for clarity and correct types\n","schema = {\n","    \"inning\": pl.Int64,\n","    \"team\": pl.Categorical, # Use categorical for efficiency\n","    \"stat\": pl.Categorical, # Use categorical for efficiency\n","    \"number\": pl.Utf8, # Keep bin labels as strings ('0', '1', ..., '5+')\n","    \"probability\": pl.Float64\n","}\n","\n","if data_for_df: # Check if list is not empty\n","    df_probabilities = pl.DataFrame(data_for_df, schema=schema)\n","\n","    print(\"\\nFinal Probability DataFrame:\")\n","    # Display sorted for readability\n","    print(df_probabilities.sort([\"inning\", \"team\", \"stat\", \"number\"]))\n","else:\n","    print(\"\\nNo data processed to create the DataFrame.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0slZ3W11f_U","executionInfo":{"status":"ok","timestamp":1745112947602,"user_tz":240,"elapsed":348,"user":{"displayName":"Sam","userId":"02456008665656849434"}},"outputId":"f953f5bb-58de-443d-8918-8415e6a1d703"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final Probability DataFrame:\n","shape: (108, 5)\n","┌────────┬──────┬──────┬────────┬─────────────┐\n","│ inning ┆ team ┆ stat ┆ number ┆ probability │\n","│ ---    ┆ ---  ┆ ---  ┆ ---    ┆ ---         │\n","│ i64    ┆ cat  ┆ cat  ┆ str    ┆ f64         │\n","╞════════╪══════╪══════╪════════╪═════════════╡\n","│ 1      ┆ away ┆ H    ┆ 0      ┆ 0.6         │\n","│ 1      ┆ away ┆ H    ┆ 1      ┆ 0.25        │\n","│ 1      ┆ away ┆ H    ┆ 2      ┆ 0.1         │\n","│ 1      ┆ away ┆ H    ┆ 3      ┆ 0.03        │\n","│ 1      ┆ away ┆ H    ┆ 4      ┆ 0.01        │\n","│ 1      ┆ away ┆ H    ┆ 5+     ┆ 0.01        │\n","│ 1      ┆ away ┆ BB   ┆ 0      ┆ 0.7         │\n","│ 1      ┆ away ┆ BB   ┆ 1      ┆ 0.2         │\n","│ 1      ┆ away ┆ BB   ┆ 2      ┆ 0.05        │\n","│ 1      ┆ away ┆ BB   ┆ 3      ┆ 0.02        │\n","│ 1      ┆ away ┆ BB   ┆ 4      ┆ 0.01        │\n","│ 1      ┆ away ┆ BB   ┆ 5+     ┆ 0.02        │\n","│ 1      ┆ away ┆ HR   ┆ 0      ┆ 0.9         │\n","│ 1      ┆ away ┆ HR   ┆ 1      ┆ 0.07        │\n","│ 1      ┆ away ┆ HR   ┆ 2      ┆ 0.02        │\n","│ 1      ┆ away ┆ HR   ┆ 3      ┆ 0.01        │\n","│ 1      ┆ away ┆ HR   ┆ 4      ┆ 0.0         │\n","│ 1      ┆ away ┆ HR   ┆ 5+     ┆ 0.0         │\n","│ 1      ┆ home ┆ H    ┆ 0      ┆ 0.55        │\n","│ 1      ┆ home ┆ H    ┆ 1      ┆ 0.28        │\n","│ 1      ┆ home ┆ H    ┆ 2      ┆ 0.12        │\n","│ 1      ┆ home ┆ H    ┆ 3      ┆ 0.03        │\n","│ 1      ┆ home ┆ H    ┆ 4      ┆ 0.01        │\n","│ 1      ┆ home ┆ H    ┆ 5+     ┆ 0.01        │\n","│ 1      ┆ home ┆ BB   ┆ 0      ┆ 0.65        │\n","│ 1      ┆ home ┆ BB   ┆ 1      ┆ 0.22        │\n","│ 1      ┆ home ┆ BB   ┆ 2      ┆ 0.07        │\n","│ 1      ┆ home ┆ BB   ┆ 3      ┆ 0.03        │\n","│ 1      ┆ home ┆ BB   ┆ 4      ┆ 0.02        │\n","│ 1      ┆ home ┆ BB   ┆ 5+     ┆ 0.01        │\n","│ 1      ┆ home ┆ HR   ┆ 0      ┆ 0.88        │\n","│ 1      ┆ home ┆ HR   ┆ 1      ┆ 0.08        │\n","│ 1      ┆ home ┆ HR   ┆ 2      ┆ 0.02        │\n","│ 1      ┆ home ┆ HR   ┆ 3      ┆ 0.01        │\n","│ 1      ┆ home ┆ HR   ┆ 4      ┆ 0.01        │\n","│ 1      ┆ home ┆ HR   ┆ 5+     ┆ 0.0         │\n","│ 2      ┆ away ┆ H    ┆ 0      ┆ 0.62        │\n","│ 2      ┆ away ┆ H    ┆ 1      ┆ 0.24        │\n","│ 2      ┆ away ┆ H    ┆ 2      ┆ 0.09        │\n","│ 2      ┆ away ┆ H    ┆ 3      ┆ 0.03        │\n","│ 2      ┆ away ┆ H    ┆ 4      ┆ 0.01        │\n","│ 2      ┆ away ┆ H    ┆ 5+     ┆ 0.01        │\n","│ 2      ┆ away ┆ BB   ┆ 0      ┆ 0.72        │\n","│ 2      ┆ away ┆ BB   ┆ 1      ┆ 0.19        │\n","│ 2      ┆ away ┆ BB   ┆ 2      ┆ 0.05        │\n","│ 2      ┆ away ┆ BB   ┆ 3      ┆ 0.02        │\n","│ 2      ┆ away ┆ BB   ┆ 4      ┆ 0.01        │\n","│ 2      ┆ away ┆ BB   ┆ 5+     ┆ 0.01        │\n","│ 2      ┆ away ┆ HR   ┆ 0      ┆ 0.91        │\n","│ 2      ┆ away ┆ HR   ┆ 1      ┆ 0.06        │\n","│ 2      ┆ away ┆ HR   ┆ 2      ┆ 0.02        │\n","│ 2      ┆ away ┆ HR   ┆ 3      ┆ 0.01        │\n","│ 2      ┆ away ┆ HR   ┆ 4      ┆ 0.0         │\n","│ 2      ┆ away ┆ HR   ┆ 5+     ┆ 0.0         │\n","│ 2      ┆ home ┆ H    ┆ 0      ┆ 0.57        │\n","│ 2      ┆ home ┆ H    ┆ 1      ┆ 0.27        │\n","│ 2      ┆ home ┆ H    ┆ 2      ┆ 0.11        │\n","│ 2      ┆ home ┆ H    ┆ 3      ┆ 0.03        │\n","│ 2      ┆ home ┆ H    ┆ 4      ┆ 0.01        │\n","│ 2      ┆ home ┆ H    ┆ 5+     ┆ 0.01        │\n","│ 2      ┆ home ┆ BB   ┆ 0      ┆ 0.67        │\n","│ 2      ┆ home ┆ BB   ┆ 1      ┆ 0.21        │\n","│ 2      ┆ home ┆ BB   ┆ 2      ┆ 0.07        │\n","│ 2      ┆ home ┆ BB   ┆ 3      ┆ 0.03        │\n","│ 2      ┆ home ┆ BB   ┆ 4      ┆ 0.01        │\n","│ 2      ┆ home ┆ BB   ┆ 5+     ┆ 0.01        │\n","│ 2      ┆ home ┆ HR   ┆ 0      ┆ 0.89        │\n","│ 2      ┆ home ┆ HR   ┆ 1      ┆ 0.07        │\n","│ 2      ┆ home ┆ HR   ┆ 2      ┆ 0.02        │\n","│ 2      ┆ home ┆ HR   ┆ 3      ┆ 0.01        │\n","│ 2      ┆ home ┆ HR   ┆ 4      ┆ 0.01        │\n","│ 2      ┆ home ┆ HR   ┆ 5+     ┆ 0.0         │\n","│ 3      ┆ away ┆ H    ┆ 0      ┆ 0.61        │\n","│ 3      ┆ away ┆ H    ┆ 1      ┆ 0.26        │\n","│ 3      ┆ away ┆ H    ┆ 2      ┆ 0.08        │\n","│ 3      ┆ away ┆ H    ┆ 3      ┆ 0.03        │\n","│ 3      ┆ away ┆ H    ┆ 4      ┆ 0.01        │\n","│ 3      ┆ away ┆ H    ┆ 5+     ┆ 0.01        │\n","│ 3      ┆ away ┆ BB   ┆ 0      ┆ 0.71        │\n","│ 3      ┆ away ┆ BB   ┆ 1      ┆ 0.2         │\n","│ 3      ┆ away ┆ BB   ┆ 2      ┆ 0.05        │\n","│ 3      ┆ away ┆ BB   ┆ 3      ┆ 0.02        │\n","│ 3      ┆ away ┆ BB   ┆ 4      ┆ 0.01        │\n","│ 3      ┆ away ┆ BB   ┆ 5+     ┆ 0.01        │\n","│ 3      ┆ away ┆ HR   ┆ 0      ┆ 0.92        │\n","│ 3      ┆ away ┆ HR   ┆ 1      ┆ 0.05        │\n","│ 3      ┆ away ┆ HR   ┆ 2      ┆ 0.02        │\n","│ 3      ┆ away ┆ HR   ┆ 3      ┆ 0.01        │\n","│ 3      ┆ away ┆ HR   ┆ 4      ┆ 0.0         │\n","│ 3      ┆ away ┆ HR   ┆ 5+     ┆ 0.0         │\n","│ 3      ┆ home ┆ H    ┆ 0      ┆ 0.56        │\n","│ 3      ┆ home ┆ H    ┆ 1      ┆ 0.29        │\n","│ 3      ┆ home ┆ H    ┆ 2      ┆ 0.1         │\n","│ 3      ┆ home ┆ H    ┆ 3      ┆ 0.03        │\n","│ 3      ┆ home ┆ H    ┆ 4      ┆ 0.01        │\n","│ 3      ┆ home ┆ H    ┆ 5+     ┆ 0.01        │\n","│ 3      ┆ home ┆ BB   ┆ 0      ┆ 0.66        │\n","│ 3      ┆ home ┆ BB   ┆ 1      ┆ 0.23        │\n","│ 3      ┆ home ┆ BB   ┆ 2      ┆ 0.06        │\n","│ 3      ┆ home ┆ BB   ┆ 3      ┆ 0.03        │\n","│ 3      ┆ home ┆ BB   ┆ 4      ┆ 0.01        │\n","│ 3      ┆ home ┆ BB   ┆ 5+     ┆ 0.01        │\n","│ 3      ┆ home ┆ HR   ┆ 0      ┆ 0.9         │\n","│ 3      ┆ home ┆ HR   ┆ 1      ┆ 0.07        │\n","│ 3      ┆ home ┆ HR   ┆ 2      ┆ 0.02        │\n","│ 3      ┆ home ┆ HR   ┆ 3      ┆ 0.01        │\n","│ 3      ┆ home ┆ HR   ┆ 4      ┆ 0.0         │\n","│ 3      ┆ home ┆ HR   ┆ 5+     ┆ 0.0         │\n","└────────┴──────┴──────┴────────┴─────────────┘\n"]}]},{"cell_type":"markdown","source":["## Analyze Results"],"metadata":{"id":"PWIfsfgOvhe0"}}]}